import { useState, useEffect } from "react";
import { useOpenAI } from "./useOpenAI";
import { useSpeechSynthesis } from "./useSpeechSynthesis";

export const useSpeechRecognition = () => {
  const [isAiResponding, setIsAiResponding] = useState(false);
  const [aiResponse, setAiResponse] = useState("");
  let lastAiResponse = ""; // Track last AI response to avoid loops

  const { fetchAIResponse } = useOpenAI();
  const { speakText } = useSpeechSynthesis();

  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.error("‚ùå Speech recognition not supported in this browser.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = navigator.language || "en-US"; // Auto-detect language
    recognition.continuous = true; // ‚úÖ Keep listening continuously
    recognition.interimResults = false; // ‚úÖ Get only the final recognized speech

    recognition.onresult = async (event) => {
      if (isAiResponding) return; // ‚úÖ Prevent capturing AI's own speech

      setIsAiResponding(true);

      const spokenText = event.results[event.results.length - 1][0].transcript.trim();
      console.log("üé§ User Said:", spokenText);

      const detectedLanguage = await detectLanguage(spokenText);
      console.log(`üåç Detected Language: ${detectedLanguage}`);

      if (spokenText.toLowerCase() === lastAiResponse.toLowerCase()) {
        console.warn("üõë Ignoring AI's own response to prevent looping.");
        return;
      }

      handleDetectedSpeech(spokenText, detectedLanguage);
    };

    recognition.onerror = (error) => {
      if (error.error === "no-speech") {
        console.warn("No speech detected. Restarting...");
        setTimeout(() => recognition.start(), 5000);
        return;
      }
      console.error("Speech Recognition Error:", error);
    };

    window.speechSynthesis.addEventListener("start", () => {
      console.log("üõë Stopping speech recognition while AI is speaking...");
      recognition.abort(); // ‚úÖ Immediate stop
    });

    window.speechSynthesis.addEventListener("end", () => {
      console.log("‚úÖ AI speech finished. Resuming speech recognition...");
      setTimeout(() => {
        recognition.start();
      }, 4000);
    });

    recognition.start();
  }, []);

  async function handleDetectedSpeech(spokenText, language) {
    try {
      const aiText = await fetchAIResponse(spokenText);
      setAiResponse(aiText);
      lastAiResponse = aiText; // ‚úÖ Store last response to prevent repetition
      await speakText(aiText, language);
    } catch (error) {
      console.error("‚ùå Error processing AI response:", error);
    }
  }

  const detectLanguage = async (text) => {
    const AZURE_OPENAI_API_KEY = import.meta.env.VITE_AZURE_OPENAI_KEY;
    const AZURE_OPENAI_ENDPOINT = import.meta.env.VITE_AZURE_OPENAI_ENDPOINT;
    const DEPLOYMENT_NAME = import.meta.env.VITE_DEPLOYMENT_NAME;

    try {
      const response = await fetch(`${AZURE_OPENAI_ENDPOINT}/openai/deployments/${DEPLOYMENT_NAME}/chat/completions?api-version=2024-02-15-preview`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "api-key": AZURE_OPENAI_API_KEY,
        },
        body: JSON.stringify({
          messages: [
            { role: "system", content: "You are a language detection assistant. Identify the language of the given text and return only the language code (e.g., 'en' for English, 'es' for Spanish, 'fr' for French)." },
            { role: "user", content: text }
          ],
          max_tokens: 10
        }),
      });

      const data = await response.json();
      return data.choices[0]?.message?.content.trim() || "en"; // Default to English if detection fails
    } catch (error) {
      console.error("‚ùå Error detecting language:", error);
      return "en"; // Default fallback
    }
  };

  return { aiResponse, isAiResponding };
};
